{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n# If there's a GPU available...\nif torch.cuda.is_available():\n    # Tell PyTorch to use the GPU.\n\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n    !nvidia-smi\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"id":"9ISIOxNtPzq5","outputId":"2eef328d-a1fe-4a03-d6d7-42236787e243","execution":{"iopub.status.busy":"2023-06-19T14:44:42.247325Z","iopub.execute_input":"2023-06-19T14:44:42.247913Z","iopub.status.idle":"2023-06-19T14:44:45.956065Z","shell.execute_reply.started":"2023-06-19T14:44:42.247742Z","shell.execute_reply":"2023-06-19T14:44:45.954781Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"There are 2 GPU(s) available.\nWe will use the GPU: Tesla T4\nMon Jun 19 14:44:45 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   46C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   56C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pystemmer\n!pip install optuna==2.3.0\n# !pip install transformers #==4.2.1\n!pip install tokenizers #==0.9.4\n!pip install transformers==4.28.0\n!pip install accelerate","metadata":{"id":"070lZhfpP-hL","outputId":"95db1494-eba0-48f9-a562-ce4dc9747826","execution":{"iopub.status.busy":"2023-06-19T14:44:45.958808Z","iopub.execute_input":"2023-06-19T14:44:45.960266Z","iopub.status.idle":"2023-06-19T14:45:42.209114Z","shell.execute_reply.started":"2023-06-19T14:44:45.960233Z","shell.execute_reply":"2023-06-19T14:45:42.207884Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pystemmer in /opt/conda/lib/python3.10/site-packages (2.2.0.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: optuna==2.3.0 in /opt/conda/lib/python3.10/site-packages (2.3.0)\nRequirement already satisfied: alembic in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (1.11.1)\nRequirement already satisfied: cliff in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (4.3.0)\nRequirement already satisfied: cmaes>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (0.9.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (6.7.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (1.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (21.3)\nRequirement already satisfied: scipy!=1.4.0 in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (1.10.1)\nRequirement already satisfied: sqlalchemy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (2.0.12)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna==2.3.0) (4.64.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna==2.3.0) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (4.5.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (2.0.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic->optuna==2.3.0) (1.2.4)\nRequirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.10/site-packages (from cliff->optuna==2.3.0) (3.7.0)\nRequirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.10/site-packages (from cliff->optuna==2.3.0) (5.4.1)\nRequirement already satisfied: autopage>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from cliff->optuna==2.3.0) (0.5.1)\nRequirement already satisfied: cmd2>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from cliff->optuna==2.3.0) (2.4.3)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.10/site-packages (from cliff->optuna==2.3.0) (5.2.0)\nRequirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from cliff->optuna==2.3.0) (5.1.0)\nRequirement already satisfied: attrs>=16.3.0 in /opt/conda/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (23.1.0)\nRequirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (1.8.2)\nRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (0.2.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.4->cliff->optuna==2.3.0) (3.15.0)\nRequirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=2.0.1->cliff->optuna==2.3.0) (5.11.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic->optuna==2.3.0) (2.1.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.13.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers==4.28.0 in /opt/conda/lib/python3.10/site-packages (4.28.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.28.0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.12.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\nimport re, functools, operator, string\nimport torch , optuna, gc, random, os\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\nfrom transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers.data.processors import SingleSentenceClassificationProcessor\nfrom transformers import Trainer , TrainingArguments\nfrom transformers.trainer_utils import EvaluationStrategy\nfrom transformers.data.processors.utils import InputFeatures\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils import resample\nimport logging\nfrom sklearn.feature_selection import SelectPercentile , f_classif\nimport transformers\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\nlogging.basicConfig(level=logging.WARNING)\nlogger = logging.getLogger(__name__)","metadata":{"id":"v2xyOhxRQN5B","execution":{"iopub.status.busy":"2023-06-19T14:45:42.211278Z","iopub.execute_input":"2023-06-19T14:45:42.211655Z","iopub.status.idle":"2023-06-19T14:45:50.615925Z","shell.execute_reply.started":"2023-06-19T14:45:42.211617Z","shell.execute_reply":"2023-06-19T14:45:50.614951Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/hate-data/annot_mini_total_data.csv')","metadata":{"id":"R_4m5WHMQh0y","execution":{"iopub.status.busy":"2023-06-19T14:45:50.618995Z","iopub.execute_input":"2023-06-19T14:45:50.619643Z","iopub.status.idle":"2023-06-19T14:45:50.680027Z","shell.execute_reply.started":"2023-06-19T14:45:50.619613Z","shell.execute_reply":"2023-06-19T14:45:50.679030Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n# column_titles = ['Tweet', 'label']  # Replace with your desired column titles\n# data.columns = column_titles\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:50.681374Z","iopub.execute_input":"2023-06-19T14:45:50.681820Z","iopub.status.idle":"2023-06-19T14:45:50.699760Z","shell.execute_reply.started":"2023-06-19T14:45:50.681780Z","shell.execute_reply":"2023-06-19T14:45:50.698782Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                              Tweet    Class  \\\n0           0   البطل قاتل وجاذف بحياته لتحيا انت واطي عيب الشوم  Abusive   \n1           1  انو غريب يوجعك راسك القواتجيه عاده بيكونو بلا راس   Racism   \n2           2                طاءفي روح اسال اهل قانا وهني بخبروك   Racism   \n3           3  غرد الجحش وظن باءنه حصانا تتكلم العوني بموضوعي...  Abusive   \n4           4  الفلسطينيين واللبنانين والشاميين لكان انتو للي...   Racism   \n\n            label  type  \n0         Abusive  hate  \n1  discrimination  hate  \n2  discrimination  hate  \n3         Abusive  hate  \n4  discrimination  hate  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Tweet</th>\n      <th>Class</th>\n      <th>label</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>البطل قاتل وجاذف بحياته لتحيا انت واطي عيب الشوم</td>\n      <td>Abusive</td>\n      <td>Abusive</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>انو غريب يوجعك راسك القواتجيه عاده بيكونو بلا راس</td>\n      <td>Racism</td>\n      <td>discrimination</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>طاءفي روح اسال اهل قانا وهني بخبروك</td>\n      <td>Racism</td>\n      <td>discrimination</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>غرد الجحش وظن باءنه حصانا تتكلم العوني بموضوعي...</td>\n      <td>Abusive</td>\n      <td>Abusive</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>الفلسطينيين واللبنانين والشاميين لكان انتو للي...</td>\n      <td>Racism</td>\n      <td>discrimination</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# split normal data","metadata":{"id":"M0Vowpz7RLGe"}},{"cell_type":"code","source":"#splitting data to train and test\n# First setting the max_len , will be useful later for BERT Model\nExtra_Len = 6 # an extra padding in length , found to be useful for increasing F-score\n#Max_Len = data[\"Tweet\"].str.split().str.len().max() + Extra_Len\nfor i in range (len(data[\"Tweet\"])):\n  if len(data[\"Tweet\"][i].split())<512:\n    data[\"Tweet\"][i]=data[\"Tweet\"][i]\n  else:\n    words = data[\"Tweet\"][i].split()  # Split the string into a list of words\n    truncated_words = words[:512]  # Take only the desired number of words\n    data[\"Tweet\"][i]= ' '.join(truncated_words)\ndata = data.dropna()\nMax_Len=512\nprint(Max_Len)\n\n#Spliting the Training data\nTest_Size = 0.2\nRand_Seed = 333\n\ntrain_set, test_set = train_test_split( data, test_size= Test_Size, random_state= Rand_Seed)\n\n# print(\"Train set: \")\n# print(train_set[\"label\"].value_counts())\n# print(\"---------------------------\")\n# print (\"Test set: \")\n# print (test_set[\"label\"].value_counts())","metadata":{"id":"PG5PjWIWQye_","outputId":"ed5b3487-e13a-4edc-addf-987c2111740a","execution":{"iopub.status.busy":"2023-06-19T14:45:50.701422Z","iopub.execute_input":"2023-06-19T14:45:50.701789Z","iopub.status.idle":"2023-06-19T14:45:53.236887Z","shell.execute_reply.started":"2023-06-19T14:45:50.701758Z","shell.execute_reply":"2023-06-19T14:45:53.235884Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_14319/2431392801.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"Tweet\"][i]=data[\"Tweet\"][i]\n/tmp/ipykernel_14319/2431392801.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"Tweet\"][i]= ' '.join(truncated_words)\n","output_type":"stream"},{"name":"stdout","text":"512\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.238235Z","iopub.execute_input":"2023-06-19T14:45:53.238692Z","iopub.status.idle":"2023-06-19T14:45:53.251378Z","shell.execute_reply.started":"2023-06-19T14:45:53.238657Z","shell.execute_reply":"2023-06-19T14:45:53.250089Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                              Tweet  \\\n2192        2223                            لاشكر واجب أختي الكريمة   \n3556        3587  تعلم أصول اللغة والكتابة الصحيحة أولا الصعلوك ...   \n6603        6635  بلاش تحكم علي حد و انت فيك و فيك انت ملكش غير ...   \n1161        1186  لن ينصلح حال الشعب الفلسطيني وهذا الحمار الصهي...   \n4972        5004                   خاصكم داعش الكفار تفو العلمانيين   \n\n             Class           label    type  \n2192        normal          normal  normal  \n3556       Abusive         Abusive    hate  \n6603        normal          normal  normal  \n1161       Abusive         Abusive    hate  \n4972  religion_off  discrimination    hate  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Tweet</th>\n      <th>Class</th>\n      <th>label</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2192</th>\n      <td>2223</td>\n      <td>لاشكر واجب أختي الكريمة</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>3556</th>\n      <td>3587</td>\n      <td>تعلم أصول اللغة والكتابة الصحيحة أولا الصعلوك ...</td>\n      <td>Abusive</td>\n      <td>Abusive</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>6603</th>\n      <td>6635</td>\n      <td>بلاش تحكم علي حد و انت فيك و فيك انت ملكش غير ...</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>1161</th>\n      <td>1186</td>\n      <td>لن ينصلح حال الشعب الفلسطيني وهذا الحمار الصهي...</td>\n      <td>Abusive</td>\n      <td>Abusive</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>4972</th>\n      <td>5004</td>\n      <td>خاصكم داعش الكفار تفو العلمانيين</td>\n      <td>religion_off</td>\n      <td>discrimination</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Step 2: Create an instance of the LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Step 3: Prepare your categorical labels\nlabels = data[\"label\"]\n\n# Step 4: Fit the LabelEncoder to your labels\nlabel_encoder.fit(labels)\n\n# Step 5: Encode the categorical labels into numerical values\nlabels = label_encoder.transform(labels)\ndata[\"labels\"]=labels","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.253265Z","iopub.execute_input":"2023-06-19T14:45:53.253811Z","iopub.status.idle":"2023-06-19T14:45:53.265163Z","shell.execute_reply.started":"2023-06-19T14:45:53.253765Z","shell.execute_reply":"2023-06-19T14:45:53.264160Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data[\"labels\"]","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.266743Z","iopub.execute_input":"2023-06-19T14:45:53.267172Z","iopub.status.idle":"2023-06-19T14:45:53.279474Z","shell.execute_reply.started":"2023-06-19T14:45:53.267135Z","shell.execute_reply":"2023-06-19T14:45:53.278405Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0       0\n1       1\n2       1\n3       0\n4       1\n       ..\n6950    2\n6951    2\n6952    2\n6953    2\n6954    2\nName: labels, Length: 6955, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"\nX = data['Tweet']\ny = data['labels']\ndf=pd.DataFrame(X)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.282217Z","iopub.execute_input":"2023-06-19T14:45:53.283920Z","iopub.status.idle":"2023-06-19T14:45:53.289785Z","shell.execute_reply.started":"2023-06-19T14:45:53.283896Z","shell.execute_reply":"2023-06-19T14:45:53.288571Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"VecModel = TfidfVectorizer()\nX= VecModel.fit_transform(X)\nprint(f'The new shape for X is {X.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.291581Z","iopub.execute_input":"2023-06-19T14:45:53.292125Z","iopub.status.idle":"2023-06-19T14:45:53.542666Z","shell.execute_reply.started":"2023-06-19T14:45:53.292072Z","shell.execute_reply":"2023-06-19T14:45:53.541630Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"The new shape for X is (6955, 35975)\n","output_type":"stream"}]},{"cell_type":"code","source":"FeatureSelection = SelectPercentile(score_func = f_classif, percentile=1)\nX = FeatureSelection.fit_transform(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.544205Z","iopub.execute_input":"2023-06-19T14:45:53.544581Z","iopub.status.idle":"2023-06-19T14:45:53.576542Z","shell.execute_reply.started":"2023-06-19T14:45:53.544546Z","shell.execute_reply":"2023-06-19T14:45:53.575634Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print('X Shape is ' , X.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.580831Z","iopub.execute_input":"2023-06-19T14:45:53.581107Z","iopub.status.idle":"2023-06-19T14:45:53.586879Z","shell.execute_reply.started":"2023-06-19T14:45:53.581082Z","shell.execute_reply":"2023-06-19T14:45:53.585080Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"X Shape is  (6955, 360)\n","output_type":"stream"}]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.588536Z","iopub.execute_input":"2023-06-19T14:45:53.589245Z","iopub.status.idle":"2023-06-19T14:45:53.600324Z","shell.execute_reply.started":"2023-06-19T14:45:53.589213Z","shell.execute_reply":"2023-06-19T14:45:53.599255Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<6955x360 sparse matrix of type '<class 'numpy.float64'>'\n\twith 14760 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"train_set, test_set = train_test_split( data, test_size= Test_Size, random_state= Rand_Seed)\n\nprint(\"Train set: \")\nprint(train_set[\"labels\"].value_counts())\nprint(\"---------------------------\")\nprint (\"Test set: \")\nprint (test_set[\"labels\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.601718Z","iopub.execute_input":"2023-06-19T14:45:53.602119Z","iopub.status.idle":"2023-06-19T14:45:53.615485Z","shell.execute_reply.started":"2023-06-19T14:45:53.602087Z","shell.execute_reply":"2023-06-19T14:45:53.614309Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Train set: \n2    2821\n0    1650\n1    1093\nName: labels, dtype: int64\n---------------------------\nTest set: \n2    731\n0    377\n1    283\nName: labels, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:45:53.617132Z","iopub.execute_input":"2023-06-19T14:45:53.617557Z","iopub.status.idle":"2023-06-19T14:45:53.625832Z","shell.execute_reply.started":"2023-06-19T14:45:53.617526Z","shell.execute_reply":"2023-06-19T14:45:53.624677Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"X_train shape is  (5564, 360)\nX_test shape is  (1391, 360)\ny_train shape is  (5564,)\ny_test shape is  (1391,)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# bert model intialisation\n","metadata":{"id":"UJVIkTpFVe2e"}},{"cell_type":"code","source":"# a class representing the dataset\nclass Dataset:\n    def __init__(\n        self,\n        name,\n        train,\n        test,\n        label_list,\n    ):\n        self.name = name\n        self.train = train\n        self.test = test\n        self.label_list = label_list","metadata":{"id":"Lipb56wtQ9aU","execution":{"iopub.status.busy":"2023-06-19T14:45:53.627382Z","iopub.execute_input":"2023-06-19T14:45:53.627820Z","iopub.status.idle":"2023-06-19T14:45:53.637216Z","shell.execute_reply.started":"2023-06-19T14:45:53.627787Z","shell.execute_reply":"2023-06-19T14:45:53.636160Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BERTModelDataset(Dataset):\n    def __init__(self, text, target, model_name, max_len, label_map):\n      super(BERTModelDataset).__init__()\n      self.text = text\n      self.target = target\n      self.tokenizer_name = model_name\n      self.tokenizer = AutoTokenizer.from_pretrained(model_name,ignore_mismatched_sizes=True)\n      self.max_len = max_len\n      self.label_map = label_map\n\n    def __len__(self):\n      return len(self.text)\n\n    def __getitem__(self,item):\n      text = str(self.text[item])\n      text = \" \".join(text.split())\n\n      encoded_review = self.tokenizer.encode_plus(\n      text,\n      max_length= self.max_len,\n      add_special_tokens= True,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      truncation='longest_first',\n      return_attention_mask=True,\n      return_tensors='pt'\n    )\n      input_ids = encoded_review['input_ids'].to(device)\n      attention_mask = encoded_review['attention_mask'].to(device)\n\n      return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])","metadata":{"id":"5DZj7P5XVX65","execution":{"iopub.status.busy":"2023-06-19T14:45:53.639104Z","iopub.execute_input":"2023-06-19T14:45:53.639461Z","iopub.status.idle":"2023-06-19T14:45:53.649953Z","shell.execute_reply.started":"2023-06-19T14:45:53.639428Z","shell.execute_reply":"2023-06-19T14:45:53.648690Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Defining Needed Methods for training and evaluation\ndef model_init():\n  return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True,ignore_mismatched_sizes=True, num_labels=len(label_map))\n\ndef compute_metrics(p): #p should be of type EvalPrediction\n  preds = np.argmax(p.predictions, axis=1)\n  assert len(preds) == len(p.label_ids)\n  print(classification_report(p.label_ids,preds))\n  #print(confusion_matrix(p.label_ids,preds))\n  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n  macro_precision = precision_score(p.label_ids,preds,average='macro')\n  macro_recall = recall_score(p.label_ids,preds,average='macro')\n  acc = accuracy_score(p.label_ids,preds)\n  return {\n      'macro_f1' : macro_f1,\n      'macro_precision': macro_precision,\n      'macro_recall': macro_recall,\n      'accuracy': acc\n  }\n\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"id":"5GJzHbzPVmkA","execution":{"iopub.status.busy":"2023-06-19T14:45:53.651725Z","iopub.execute_input":"2023-06-19T14:45:53.652059Z","iopub.status.idle":"2023-06-19T14:45:53.662435Z","shell.execute_reply.started":"2023-06-19T14:45:53.652029Z","shell.execute_reply":"2023-06-19T14:45:53.661353Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"Model_Used = \"UBC-NLP/MARBERT\"\nTask_Name = \"classification\"\nMax_Len = 512\nOutput_File = \"sub_filew.csv\"\n#define training arguments\ntraining_args = transformers.TrainingArguments(\n'marbert_multi20_class',\nsave_strategy=\"epoch\",\nsave_total_limit=5,\n# push_to_hub_model_type=\"pt\",\nlr_scheduler_type='cosine',\n# evaluate_during_training=evaluate_during_training,\nadam_epsilon=1e-8,\nlearning_rate=1.215e-05,\nfp16=True,\nper_device_train_batch_size=8,\nper_device_eval_batch_size=8,\ngradient_accumulation_steps=2,\nnum_train_epochs=20,\nwarmup_steps=0,\nevaluation_strategy='epoch',\nseed=42,\ndisable_tqdm=False,\ndataloader_pin_memory=False,\n\n)\n\n\n\n","metadata":{"id":"T__ZeXA7VqCg","outputId":"32c9bec2-4a22-4f08-9df9-8e8c7d0414e5","execution":{"iopub.status.busy":"2023-06-19T14:45:53.663977Z","iopub.execute_input":"2023-06-19T14:45:53.664673Z","iopub.status.idle":"2023-06-19T14:45:53.681336Z","shell.execute_reply.started":"2023-06-19T14:45:53.664639Z","shell.execute_reply":"2023-06-19T14:45:53.680150Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"label_list = list(train_set[\"labels\"].unique())\n\nprint(label_list)\nprint(train_set[\"labels\"].value_counts())\n\ndata_set = Dataset( \"hateclass\", train_set, test_set, label_list )\n\nlabel_map = { v:index for index, v in enumerate(label_list) }\nprint(label_map)\n\ntrain_dataset = BERTModelDataset(train_set[\"Tweet\"].to_list(),\n                                 train_set[\"labels\"].to_list(),Model_Used,int(Max_Len),label_map)\n\ntest_dataset = BERTModelDataset(test_set[\"Tweet\"].to_list(),\n                                      test_set[\"labels\"].to_list(),Model_Used,int(Max_Len),label_map)","metadata":{"id":"xjHK7vSYV6hR","outputId":"99ae7146-ac4c-420e-e207-a2342aa052eb","execution":{"iopub.status.busy":"2023-06-19T14:45:53.683444Z","iopub.execute_input":"2023-06-19T14:45:53.684282Z","iopub.status.idle":"2023-06-19T14:45:54.287911Z","shell.execute_reply.started":"2023-06-19T14:45:53.684248Z","shell.execute_reply":"2023-06-19T14:45:54.286901Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[2, 0, 1]\n2    2821\n0    1650\n1    1093\nName: labels, dtype: int64\n{2: 0, 0: 1, 1: 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args.dataloader_pin_memory = False\ngc.collect()\ntorch.cuda.empty_cache()\nset_seed(Rand_Seed)\n\ntrainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset= test_dataset,\n    compute_metrics=compute_metrics\n)\n\nprint(training_args.seed)","metadata":{"id":"hqsp6WvoV-IJ","outputId":"d65aceda-9656-497c-fc43-e75450ac9e3d","execution":{"iopub.status.busy":"2023-06-19T14:45:54.289434Z","iopub.execute_input":"2023-06-19T14:45:54.289818Z","iopub.status.idle":"2023-06-19T14:46:05.281816Z","shell.execute_reply.started":"2023-06-19T14:45:54.289783Z","shell.execute_reply":"2023-06-19T14:46:05.279989Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"42\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf /kaggle/working/wandb","metadata":{"execution":{"iopub.status.busy":"2023-06-19T14:50:36.311023Z","iopub.execute_input":"2023-06-19T14:50:36.311393Z","iopub.status.idle":"2023-06-19T14:50:37.371621Z","shell.execute_reply.started":"2023-06-19T14:50:36.311360Z","shell.execute_reply":"2023-06-19T14:50:37.370241Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import os\ngc.collect()\ntorch.cuda.empty_cache()\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ntrainer.train()","metadata":{"id":"ytBucl1gWDKD","outputId":"0c6b28ff-9530-477a-c302-bec415201f3a","execution":{"iopub.status.busy":"2023-06-19T14:50:40.823521Z","iopub.execute_input":"2023-06-19T14:50:40.824469Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1045' max='3480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1045/3480 17:43 < 41:23, 0.98 it/s, Epoch 6/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Macro F1</th>\n      <th>Macro Precision</th>\n      <th>Macro Recall</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.555381</td>\n      <td>0.699259</td>\n      <td>0.706562</td>\n      <td>0.693713</td>\n      <td>0.754134</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.571081</td>\n      <td>0.743473</td>\n      <td>0.735609</td>\n      <td>0.765703</td>\n      <td>0.767793</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.492400</td>\n      <td>0.571303</td>\n      <td>0.768553</td>\n      <td>0.762978</td>\n      <td>0.776036</td>\n      <td>0.798706</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.492400</td>\n      <td>0.751510</td>\n      <td>0.759906</td>\n      <td>0.756025</td>\n      <td>0.775352</td>\n      <td>0.785766</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.492400</td>\n      <td>0.917307</td>\n      <td>0.775717</td>\n      <td>0.770632</td>\n      <td>0.782099</td>\n      <td>0.808052</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='36' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [36/87 00:06 < 00:08, 5.81 it/s]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.84      0.89      0.87       731\n           1       0.67      0.64      0.65       377\n           2       0.61      0.55      0.58       283\n\n    accuracy                           0.75      1391\n   macro avg       0.71      0.69      0.70      1391\nweighted avg       0.75      0.75      0.75      1391\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.94      0.78      0.85       731\n           1       0.68      0.74      0.71       377\n           2       0.59      0.78      0.67       283\n\n    accuracy                           0.77      1391\n   macro avg       0.74      0.77      0.74      1391\nweighted avg       0.80      0.77      0.78      1391\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       731\n           1       0.70      0.76      0.73       377\n           2       0.68      0.72      0.70       283\n\n    accuracy                           0.80      1391\n   macro avg       0.76      0.78      0.77      1391\nweighted avg       0.81      0.80      0.80      1391\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.94      0.80      0.86       731\n           1       0.65      0.83      0.73       377\n           2       0.67      0.70      0.69       283\n\n    accuracy                           0.79      1391\n   macro avg       0.76      0.78      0.76      1391\nweighted avg       0.81      0.79      0.79      1391\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89       731\n           1       0.72      0.77      0.74       377\n           2       0.67      0.71      0.69       283\n\n    accuracy                           0.81      1391\n   macro avg       0.77      0.78      0.78      1391\nweighted avg       0.81      0.81      0.81      1391\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## aubmindlab/bert-base-arabertv2","metadata":{"id":"YdTq3ikgW_D3"}},{"cell_type":"code","source":"Model_Used = \"lamaabdulaziz/AraBERT-finetuned-CrossVal-fnd\"\nTask_Name = \"classification\"\nMax_Len = 512\nOutput_File = \"sub_filew.csv\"\n#define training arguments\n\ntraining_args = transformers.TrainingArguments(\n'arabert',\nsave_strategy=\"epoch\",\nsave_total_limit=5,\n# push_to_hub_model_type=\"pt\",\nlr_scheduler_type='cosine',\n# evaluate_during_training=evaluate_during_training,\nadam_epsilon=1e-8,\nlearning_rate=2e-05,\nfp16=True,\nper_device_train_batch_size=8,\nper_device_eval_batch_size=8,\ngradient_accumulation_steps=2,\nnum_train_epochs=4,\nwarmup_steps=0,\nevaluation_strategy='epoch',\nseed=42,\ndisable_tqdm=False,\ndataloader_pin_memory=False,\n\n)\n","metadata":{"id":"-5mIlzfUWxw5","outputId":"5708a8aa-43da-487c-aca6-d6ac10c673d6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_list = list(train_set[\"label\"].unique())\n\nprint(label_list)\nprint(train_set[\"label\"].value_counts())\n\ndata_set = Dataset( \"3hsd\", train_set, test_set, label_list )\n\nlabel_map = { v:index for index, v in enumerate(label_list) }\nprint(label_map)\n\ntrain_dataset = BERTModelDataset(train_set[\"Tweet\"].to_list(),\n                                 train_set[\"label\"].to_list(),Model_Used,int(Max_Len),label_map)\n\ntest_dataset = BERTModelDataset(test_set[\"Tweet\"].to_list(),\n                                      test_set[\"label\"].to_list(),Model_Used,int(Max_Len),label_map)","metadata":{"id":"5HC51p12XZqB","outputId":"a8179cd9-0b00-44ed-ee82-556c4352addb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args.dataloader_pin_memory = False\ngc.collect()\ntorch.cuda.empty_cache()\nset_seed(Rand_Seed)\n\ntrainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset= test_dataset,\n    compute_metrics=compute_metrics\n)\n\nprint(training_args.seed)","metadata":{"id":"Nj1KOuP1XZeD","outputId":"2446c03e-115a-4557-813a-c061b31acf61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ngc.collect()\ntorch.cuda.empty_cache()\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ntrainer.train()","metadata":{"id":"PBg4jKrJXZbm","outputId":"35ee2151-ffad-43d7-d9d1-d26abb4b16bf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# camel_bert","metadata":{}},{"cell_type":"code","source":"Model_Used = \"CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment\"\nTask_Name = \"classification\"\nMax_Len = 512\n\n#define training arguments\n\ntraining_args = transformers.TrainingArguments(\n'camel_mix_sentiment',\nsave_strategy=\"epoch\",\nsave_total_limit=5,\n# push_to_hub_model_type=\"pt\",\nlr_scheduler_type='cosine',\n# evaluate_during_training=evaluate_during_training,\nadam_epsilon=1e-8,\nlearning_rate=2e-05,\nfp16=True,\nper_device_train_batch_size=8,\nper_device_eval_batch_size=8,\ngradient_accumulation_steps=2,\nnum_train_epochs=4,\nwarmup_steps=0,\nevaluation_strategy='epoch',\nseed=42,\ndisable_tqdm=False,\ndataloader_pin_memory=False,\n\n)\n","metadata":{"id":"ReALB2fjYaVS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_list = list(train_set[\"label\"].unique())\n\nprint(label_list)\nprint(train_set[\"label\"].value_counts())\n\ndata_set = Dataset( \"3hsd\", train_set, test_set, label_list )\n\nlabel_map = { v:index for index, v in enumerate(label_list) }\nprint(label_map)\n\ntrain_dataset = BERTModelDataset(train_set[\"Tweet\"].to_list(),\n                                 train_set[\"label\"].to_list(),Model_Used,int(Max_Len),label_map)\n\ntest_dataset = BERTModelDataset(test_set[\"Tweet\"].to_list(),\n                                      test_set[\"label\"].to_list(),Model_Used,int(Max_Len),label_map)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args.dataloader_pin_memory = False\ngc.collect()\ntorch.cuda.empty_cache()\nset_seed(Rand_Seed)\n\ntrainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset= test_dataset,\n    compute_metrics=compute_metrics\n)\n\nprint(training_args.seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ngc.collect()\ntorch.cuda.empty_cache()\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}